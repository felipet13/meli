{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866f8cb",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0, \"packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de56813",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.environ.get(\"CIRCLECI\"):\n",
    "    default_env = os.environ.get(\"CONDA_DEFAULT_ENV\")\n",
    "    os.environ[\"PYSPARK_DRIVER_PYTHON\"] = (\n",
    "        f\"/home/circleci/miniconda/envs/{default_env}/bin/python\"\n",
    "    )\n",
    "    os.environ[\"PYSPARK_PYTHON\"] = (\n",
    "        f\"/home/circleci/miniconda/envs/{default_env}/bin/python\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe25b40",
   "metadata": {},
   "source": [
    "# Feature Generation - Case study\n",
    "\n",
    "## Overview:\n",
    "This document explains how various feature generation components could be utilised to create a typical pipeline. Note we will be using the `nodes` functions rather than the `core` functions to simulate parametrisation from a pipeline. The same can all be done in code using the `core` functions. \n",
    "\n",
    "\n",
    "## Use case:\n",
    "We want to analyse the shopping pattern of customers for a chain of supermarkets.\n",
    "\n",
    "Our end goal is to create the following list of features:\n",
    "\n",
    "- Number of orders placed by female customers in last 6 months at a given store.\n",
    "- Number of orders placed by female customers over 60 years in last 6 months at a given store.\n",
    "- Number of orders containing groceries in last 6 months.\n",
    "- Percentage of orders placed by female customers over 60 years in last 6 months at a given store.\n",
    "\n",
    "\n",
    "We will be using the following dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc37e3b",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    DateType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.ui.showConsoleProgress\", False).getOrCreate()\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"store_id\", StringType(), True),\n",
    "        StructField(\"order_id\", IntegerType(), True),\n",
    "        StructField(\"product_id\", StringType(), True),\n",
    "        StructField(\"product_name\", StringType(), True),\n",
    "        StructField(\"quantity\", IntegerType(), True),\n",
    "        StructField(\"price\", IntegerType(), True),\n",
    "        StructField(\"observation_dt\", DateType(), True),\n",
    "        StructField(\"cust_id\", StringType(), True),\n",
    "        StructField(\"cust_age\", IntegerType(), True),\n",
    "        StructField(\"cust_gender\", StringType(), True),\n",
    "        StructField(\"month_index\", IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "data = [\n",
    "    (\n",
    "        \"s1\",\n",
    "        1,\n",
    "        \"A\",\n",
    "        \"prod_a\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-03-01\").date(),\n",
    "        \"c1\",\n",
    "        62,\n",
    "        \"f\",\n",
    "        103,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        1,\n",
    "        \"A\",\n",
    "        \"prod_a\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-03-01\").date(),\n",
    "        \"c1\",\n",
    "        62,\n",
    "        \"f\",\n",
    "        103,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        2,\n",
    "        \"B\",\n",
    "        \"prod_b\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-01-01\").date(),\n",
    "        \"c1\",\n",
    "        22,\n",
    "        \"m\",\n",
    "        101,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        3,\n",
    "        \"C\",\n",
    "        \"prod_c\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-02-01\").date(),\n",
    "        \"c1\",\n",
    "        42,\n",
    "        \"f\",\n",
    "        102,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        3,\n",
    "        \"C\",\n",
    "        \"prod_c\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-02-01\").date(),\n",
    "        \"c1\",\n",
    "        42,\n",
    "        \"f\",\n",
    "        102,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        4,\n",
    "        \"B\",\n",
    "        \"prod_b\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-04-01\").date(),\n",
    "        \"c1\",\n",
    "        22,\n",
    "        \"m\",\n",
    "        104,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        4,\n",
    "        \"B\",\n",
    "        \"prod_b\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-04-01\").date(),\n",
    "        \"c1\",\n",
    "        22,\n",
    "        \"m\",\n",
    "        104,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        4,\n",
    "        \"B\",\n",
    "        \"prod_b\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-04-01\").date(),\n",
    "        \"c1\",\n",
    "        22,\n",
    "        \"m\",\n",
    "        104,\n",
    "    ),\n",
    "    (\n",
    "        \"s2\",\n",
    "        5,\n",
    "        \"D\",\n",
    "        \"prod_d\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-05-01\").date(),\n",
    "        \"c1\",\n",
    "        65,\n",
    "        \"f\",\n",
    "        105,\n",
    "    ),\n",
    "    (\n",
    "        \"s2\",\n",
    "        5,\n",
    "        \"D\",\n",
    "        \"prod_d\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-05-01\").date(),\n",
    "        \"c1\",\n",
    "        65,\n",
    "        \"f\",\n",
    "        105,\n",
    "    ),\n",
    "    (\n",
    "        \"s3\",\n",
    "        6,\n",
    "        \"E\",\n",
    "        \"prod_e\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-03-01\").date(),\n",
    "        \"c1\",\n",
    "        65,\n",
    "        \"m\",\n",
    "        103,\n",
    "    ),\n",
    "    (\n",
    "        \"s3\",\n",
    "        7,\n",
    "        \"F\",\n",
    "        \"prod_f\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-01-01\").date(),\n",
    "        \"c1\",\n",
    "        61,\n",
    "        \"f\",\n",
    "        101,\n",
    "    ),\n",
    "    (\n",
    "        \"s3\",\n",
    "        7,\n",
    "        \"F\",\n",
    "        \"prod_f\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-01-01\").date(),\n",
    "        \"c1\",\n",
    "        61,\n",
    "        \"f\",\n",
    "        101,\n",
    "    ),\n",
    "    (\n",
    "        \"s3\",\n",
    "        8,\n",
    "        \"G\",\n",
    "        \"prod_g\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-04-01\").date(),\n",
    "        \"c1\",\n",
    "        32,\n",
    "        \"f\",\n",
    "        104,\n",
    "    ),\n",
    "    (\n",
    "        \"s3\",\n",
    "        8,\n",
    "        \"G\",\n",
    "        \"prod_g\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-04-01\").date(),\n",
    "        \"c1\",\n",
    "        32,\n",
    "        \"f\",\n",
    "        104,\n",
    "    ),\n",
    "    (\n",
    "        \"s3\",\n",
    "        9,\n",
    "        \"H\",\n",
    "        \"prod_h\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-05-01\").date(),\n",
    "        \"c1\",\n",
    "        41,\n",
    "        \"m\",\n",
    "        105,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        10,\n",
    "        \"I\",\n",
    "        \"prod_i\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-06-01\").date(),\n",
    "        \"c1\",\n",
    "        62,\n",
    "        \"m\",\n",
    "        106,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        10,\n",
    "        \"I\",\n",
    "        \"prod_i\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-06-01\").date(),\n",
    "        \"c1\",\n",
    "        62,\n",
    "        \"m\",\n",
    "        106,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        10,\n",
    "        \"I\",\n",
    "        \"prod_i\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-06-01\").date(),\n",
    "        \"c1\",\n",
    "        62,\n",
    "        \"m\",\n",
    "        106,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        11,\n",
    "        \"J\",\n",
    "        \"prod_j\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-07-01\").date(),\n",
    "        \"c1\",\n",
    "        21,\n",
    "        \"f\",\n",
    "        107,\n",
    "    ),\n",
    "    (\n",
    "        \"s4\",\n",
    "        12,\n",
    "        \"J\",\n",
    "        \"prod_j\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-02-01\").date(),\n",
    "        \"c1\",\n",
    "        21,\n",
    "        \"f\",\n",
    "        102,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        13,\n",
    "        \"A\",\n",
    "        \"prod_a\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-01-01\").date(),\n",
    "        \"c1\",\n",
    "        62,\n",
    "        \"f\",\n",
    "        101,\n",
    "    ),\n",
    "    (\n",
    "        \"s4\",\n",
    "        14,\n",
    "        \"C\",\n",
    "        \"prod_c\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-01-01\").date(),\n",
    "        \"c1\",\n",
    "        42,\n",
    "        \"f\",\n",
    "        101,\n",
    "    ),\n",
    "    (\n",
    "        \"s1\",\n",
    "        11,\n",
    "        \"J\",\n",
    "        \"prod_j\",\n",
    "        1,\n",
    "        10,\n",
    "        pd.Timestamp(\"2021-01-01\").date(),\n",
    "        \"c1\",\n",
    "        21,\n",
    "        \"f\",\n",
    "        101,\n",
    "    ),\n",
    "]\n",
    "df_events = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa45982",
   "metadata": {},
   "source": [
    "## Components:\n",
    "\n",
    "### Primary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df78112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff32edf",
   "metadata": {},
   "source": [
    "### Tags creation:\n",
    "Rows in the primary table are tagged based on requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b0e9c",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "tag_config_string = \"\"\"\n",
    "  - \"tag\": \"female\"\n",
    "    \"object\": \"feature_generation.v1.core.tags.tags.isin\"\n",
    "    \"input\": \"cust_gender\"\n",
    "    \"values\": [ \"f\" ]\n",
    "  - \"tag\": \"over60\"\n",
    "    \"object\": \"feature_generation.v1.core.tags.tags.expr_tag\"\n",
    "    \"expr\": \"cust_age > 60\"\n",
    "  - \"tag\": \"grocery\"\n",
    "    \"object\": \"feature_generation.v1.core.tags.tags.isin\"\n",
    "    \"input\": \"product_name\"\n",
    "    \"values\": [\"prod_a\", \"prod_c\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_generation.v1.nodes.tags.generate_tags import create_tags_from_config\n",
    "\n",
    "print(tag_config_string)\n",
    "tag_config = yaml.safe_load(tag_config_string)\n",
    "df_tag = create_tags_from_config(df_events, tag_config)\n",
    "df_tag.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99d572",
   "metadata": {},
   "source": [
    "### Expand tags/Conversion to flags: Tags are converted to individual flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b21241",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tags = [\"female\", \"over60\", \"grocery\"]\n",
    "\n",
    "key_cols = [\"store_id\", \"observation_dt\", \"month_index\"]\n",
    "\n",
    "column_instructions = {\n",
    "    \"is_female\": {\n",
    "        \"object\": \"pyspark.sql.functions.max\",\n",
    "        \"col\": \"female\",\n",
    "    },\n",
    "    \"cust_age_over_60\": {\n",
    "        \"object\": \"pyspark.sql.functions.max\",\n",
    "        \"col\": \"over60\",\n",
    "    },\n",
    "    \"grocery\": {\n",
    "        \"object\": \"pyspark.sql.functions.max\",\n",
    "        \"col\": \"grocery\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "from feature_generation.v1.nodes.tags.expand_tags import expand_tags, expand_tags_all\n",
    "\n",
    "# Option 1: Giving explicit list of tags\n",
    "expand_tags_df = expand_tags(\n",
    "    df_with_tags=df_tag,\n",
    "    tags_to_convert=list_of_tags,\n",
    ")\n",
    "\n",
    "# Option 2: Expanding all tags automatically\n",
    "expand_tags_all_df = expand_tags_all(\n",
    "    df_with_tags=df_tag,\n",
    ")\n",
    "\n",
    "expand_tags_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5046b",
   "metadata": {},
   "source": [
    "### Derived flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69448ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_generation.v1.nodes.features.create_column import (\n",
    "    create_columns_from_config,\n",
    ")\n",
    "\n",
    "flags_config = [\n",
    "    {\n",
    "        \"object\": \"feature_generation.v1.core.features.flags.expr_col\",\n",
    "        \"output\": \"is_female_over60\",\n",
    "        \"expr\": \"case when female = 1 and over60 = 1 then 1 else 0 end\",\n",
    "    },\n",
    "]\n",
    "\n",
    "df_flags = create_columns_from_config(expand_tags_df, flags_config)\n",
    "\n",
    "df_flags.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d4cfe",
   "metadata": {},
   "source": [
    "### Aggregate: Aggregate flags at spine's granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_generation.v1.nodes.aggregation.aggregate import aggregate_attributes\n",
    "\n",
    "key_cols = [\"store_id\", \"observation_dt\", \"month_index\"]\n",
    "\n",
    "agg_config = {\n",
    "    \"ftr_cnt_female_orders\": {\n",
    "        \"object\": \"pyspark.sql.functions.sum\",\n",
    "        \"col\": \"female\",\n",
    "    },\n",
    "    \"ftr_cnt_total_orders\": {\n",
    "        \"object\": \"pyspark.sql.functions.count\",\n",
    "        \"col\": \"order_id\",\n",
    "    },\n",
    "    \"ftr_cnt_female_over60_orders\": {\n",
    "        \"object\": \"pyspark.sql.functions.sum\",\n",
    "        \"col\": \"is_female_over60\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "df_agg = aggregate_attributes(\n",
    "    df=df_flags, key_cols=key_cols, column_instructions=agg_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73504df6",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "df_agg = df_agg.orderBy(\"store_id\", \"observation_dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf532fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3138aa0",
   "metadata": {},
   "source": [
    "### Windows: Calculate features over required windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b51386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_generation.v1.nodes.features.create_column import (\n",
    "    create_columns_from_config,\n",
    ")\n",
    "\n",
    "window_grid_config = [\n",
    "    {\n",
    "        \"object\": \"feature_generation.v1.core.features.windows.generate_window_grid\",\n",
    "        \"inputs\": [\n",
    "            \"ftr_cnt_female_orders\",\n",
    "            \"ftr_cnt_total_orders\",\n",
    "            \"ftr_cnt_female_over60_orders\",\n",
    "        ],\n",
    "        \"funcs\": [\n",
    "            {\"object\": \"pyspark.sql.functions.sum\"},\n",
    "        ],\n",
    "        \"windows\": [\n",
    "            {\"partition_by\": [\"store_id\"], \"order_by\": [\"month_index\"]},\n",
    "        ],\n",
    "        \"ranges_between\": [\n",
    "            [-6, -1],\n",
    "            [-4, -1],\n",
    "        ],\n",
    "        \"suffix\": \"m\",\n",
    "    },\n",
    "]\n",
    "\n",
    "df_windows_grid = create_columns_from_config(df_agg, window_grid_config)\n",
    "\n",
    "df_windows_grid.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c413f0d",
   "metadata": {},
   "source": [
    "### Derived windows: Create derived window features (example: percentage over window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_generation.v1.nodes.features.create_column import (\n",
    "    create_columns_from_config,\n",
    ")\n",
    "\n",
    "derived_config = [\n",
    "    {\n",
    "        \"object\": \"feature_generation.v1.core.features.flags.expr_col\",\n",
    "        \"output\": \"ftr_perc_female_orders_sum_past_6_past_1m\",\n",
    "        \"expr\": \"ftr_cnt_female_orders_sum_past_6_past_1m/ftr_cnt_total_orders_sum_past_6_past_1m\",\n",
    "    },\n",
    "]\n",
    "\n",
    "df_windows_derived = create_columns_from_config(df_windows_grid, derived_config)\n",
    "\n",
    "df_windows_derived.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3467200",
   "metadata": {},
   "source": [
    "### Alternative step to generate windows and derived windows\n",
    "\n",
    "Since windows and derived windows both utilise the same function and input dataframe, they could be clubbed into a single node with each step running in series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a9231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_generation.v1.nodes.features.create_column import (\n",
    "    create_columns_from_config,\n",
    ")\n",
    "\n",
    "feature_config = [\n",
    "    {\n",
    "        \"object\": \"feature_generation.v1.core.features.windows.generate_window_grid\",\n",
    "        \"inputs\": [\n",
    "            \"ftr_cnt_female_orders\",\n",
    "            \"ftr_cnt_total_orders\",\n",
    "            \"ftr_cnt_female_over60_orders\",\n",
    "        ],\n",
    "        \"funcs\": [\n",
    "            {\"object\": \"pyspark.sql.functions.sum\"},\n",
    "        ],\n",
    "        \"windows\": [\n",
    "            {\"partition_by\": [\"store_id\"], \"order_by\": [\"month_index\"]},\n",
    "        ],\n",
    "        \"ranges_between\": [\n",
    "            [-6, -1],\n",
    "            [-4, -1],\n",
    "        ],\n",
    "        \"suffix\": \"m\",\n",
    "    },\n",
    "    {\n",
    "        \"object\": \"feature_generation.v1.core.features.flags.expr_col\",\n",
    "        \"output\": \"ftr_perc_female_orders_sum_past_6_past_1m\",\n",
    "        \"expr\": \"ftr_cnt_female_orders_sum_past_6_past_1m/ftr_cnt_total_orders_sum_past_6_past_1m\",\n",
    "    },\n",
    "]\n",
    "\n",
    "df_overall_features = create_columns_from_config(\n",
    "    df=df_agg, column_instructions=feature_config, sequential=True\n",
    ")\n",
    "\n",
    "df_overall_features.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
