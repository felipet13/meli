# Changelog

## 0.6.4
|    | Function Name                                                                        | Type   | Old Signature                                                                                                                                                                                                                                                                                                                                                                                                                   | New Signature                                                                                                                                                                                                                                                                                                                                                                                                                                                |
|---:|:-------------------------------------------------------------------------------------|:-------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | `feature_generation.v1.core.features.create_column.create_columns_from_config`       | Change | `(df: pyspark.sql.dataframe.DataFrame, column_instructions: List[Callable], sequential: bool = False, params_keep_cols: List[str] = None, enable_regex: bool = False) -> pyspark.sql.dataframe.DataFrame`                                                                                                                                                                                                                       | `(df: pyspark.sql.dataframe.DataFrame, column_instructions: List[Callable], sequential: bool = False, params_keep_cols: Optional[List[str]] = None, enable_regex: bool = False) -> pyspark.sql.dataframe.DataFrame`                                                                                                                                                                                                                                          |
|  1 | `feature_generation.v1.core.features.custom_windows.complete_max`                    | Change | `(n_rows: int, null_value: str = None, return_dtype: str = 'double') -> Callable`                                                                                                                                                                                                                                                                                                                                               | `(n_rows: int, null_value: Optional[str] = None, return_dtype: str = 'double') -> Callable`                                                                                                                                                                                                                                                                                                                                                                  |
|  2 | `feature_generation.v1.core.features.custom_windows.complete_sum`                    | Change | `(n_rows: int, null_value: str = None, return_dtype: str = 'double') -> Callable`                                                                                                                                                                                                                                                                                                                                               | `(n_rows: int, null_value: Optional[str] = None, return_dtype: str = 'double') -> Callable`                                                                                                                                                                                                                                                                                                                                                                  |
|  3 | `feature_generation.v1.core.features.flags.arrays_overlap`                           | Change | `(input: str, values: Union[str, List[str]], output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                               | `(input: str, values: Union[str, List[str]], output: str, return_value: Optional[str] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                                  |
|  4 | `feature_generation.v1.core.features.flags.expr_flag`                                | Change | `(expr: str, output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                                               | `(expr: str, output: str, return_value: Optional[str] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                                                                  |
|  5 | `feature_generation.v1.core.features.flags.isin`                                     | Change | `(input: str, values: List[str], output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                           | `(input: str, values: List[str], output: str, return_value: Optional[str] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                                              |
|  6 | `feature_generation.v1.core.features.flags.nth_occurrence`                           | Change | `(output: str, input: str, values: str, window: Dict[str, Union[str, List[str]]], n: int, return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                               | `(output: str, input: str, values: str, window: Dict[str, Union[str, List[str]]], n: int, return_value: Optional[str] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  |
|  7 | `feature_generation.v1.core.features.flags.rlike`                                    | Change | `(input: str, values: Union[str, List[str]], output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                               | `(input: str, values: Union[str, List[str]], output: str, return_value: Optional[str] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                                  |
|  8 | `feature_generation.v1.core.features.flags.rlike_extract`                            | Change | `(input: str, values: List[str], output: str, suffix: str = None, return_value: str = None) -> List[pyspark.sql.column.Column]`                                                                                                                                                                                                                                                                                                 | `(input: str, values: List[str], output: str, suffix: Optional[str] = None, return_value: Optional[str] = None) -> List[pyspark.sql.column.Column]`                                                                                                                                                                                                                                                                                                          |
|  9 | `feature_generation.v1.core.features.flags.tag_arrays_overlap`                       | Change | `(input: str, values: Union[str, List[str]], output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                               | `(input: str, values: Union[str, List[str]], output: str, return_value: Optional[str] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                                  |
| 10 | `feature_generation.v1.core.features.interactions.create_interaction_features`       | Change | `(df: pyspark.sql.dataframe.DataFrame, params_interaction: List[Dict[str, List[str]]], params_spine_cols: List[str] = None, keep_new_cols: bool = True) -> pyspark.sql.dataframe.DataFrame`                                                                                                                                                                                                                                     | `(df: pyspark.sql.dataframe.DataFrame, params_interaction: List[Dict[str, List[str]]], params_spine_cols: Optional[List[str]] = None, keep_new_cols: bool = True) -> pyspark.sql.dataframe.DataFrame`                                                                                                                                                                                                                                                        |
| 11 | `feature_generation.v1.core.features.windows.generate_array_elements_window_grid`    | Change | `(inputs: List[str], windows: List[Dict[str, List[str]]], agg_functions: List[Callable], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]]` | `(inputs: List[str], windows: List[Dict[str, List[str]]], agg_functions: List[Callable], ranges_between: Optional[List[List[Union[int, str]]]] = None, rows_between: Optional[List[List[Union[int, str]]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]]`          |
| 12 | `feature_generation.v1.core.features.windows.generate_distinct_element_window_grid`  | Change | `(inputs: List[str], windows: List[Dict[str, List[str]]], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', agg_func_name: str = 'count', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]]`  | `(inputs: List[str], windows: List[Dict[str, List[str]]], ranges_between: Optional[List[List[Union[int, str]]]] = None, rows_between: Optional[List[List[Union[int, str]]]] = None, positive_term: str = 'next', negative_term: str = 'past', agg_func_name: str = 'count', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]]`           |
| 13 | `feature_generation.v1.core.features.windows.generate_window_delta`                  | Change | `(inputs: List[str], funcs: List[Callable], windows: List[Dict[str, List[str]]], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]`                                      | `(inputs: List[str], funcs: List[Callable], windows: List[Dict[str, List[str]]], ranges_between: Optional[List[List[Union[int, str]]]] = None, rows_between: Optional[List[List[Union[int, str]]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]`                                               |
| 14 | `feature_generation.v1.core.features.windows.generate_window_grid`                   | Change | `(funcs: List[Callable], windows: List[Dict[str, List[str]]], inputs: List[str] = None, ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]]`  | `(funcs: List[Callable], windows: List[Dict[str, List[str]]], inputs: Optional[List[str]] = None, ranges_between: Optional[List[List[Union[int, str]]]] = None, rows_between: Optional[List[List[Union[int, str]]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]]` |
| 15 | `feature_generation.v1.core.features.windows.generate_window_ratio`                  | Change | `(inputs: Dict[Any, Any], funcs: List[Callable], windows: List[Dict[str, List[str]]], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]`                                 | `(inputs: Dict[Any, Any], funcs: List[Callable], windows: List[Dict[str, List[str]]], ranges_between: Optional[List[List[Union[int, str]]]] = None, rows_between: Optional[List[List[Union[int, str]]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]`                                          |
| 16 | `feature_generation.v1.core.features.windows.generate_windows_spec`                  | Change | `(partition_by: Union[List[str], str], order_by: Union[List[str], str] = None, range_between: Union[List[Union[int, str]], List[List[Union[int, str]]]] = None, rows_between: Union[List[Union[int, str]], List[List[Union[int, str]]]] = None, descending: bool = False) -> List[pyspark.sql.window.WindowSpec]`                                                                                                               | `(partition_by: Union[List[str], str], order_by: Union[str, List[str], NoneType] = None, range_between: Union[List[Union[int, str]], List[List[Union[int, str]]], NoneType] = None, rows_between: Union[List[Union[int, str]], List[List[Union[int, str]]], NoneType] = None, descending: bool = False) -> List[pyspark.sql.window.WindowSpec]`                                                                                                              |
| 17 | `feature_generation.v1.core.interpolation.linear.interpolation_linear`               | Change | `(start_col: Union[str, pyspark.sql.column.Column], end_col: Union[str, pyspark.sql.column.Column], step_size: Union[int, str] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                            | `(start_col: Union[str, pyspark.sql.column.Column], end_col: Union[str, pyspark.sql.column.Column], step_size: Union[int, str, NoneType] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                               |
| 18 | `feature_generation.v1.core.tags.expand_tags.expand_tags`                            | Change | `(df_with_tags: pyspark.sql.dataframe.DataFrame, tags_to_convert: List[str], tag_col_name: str = 'tags', params_keep_cols: List[str] = None, key_cols: List[str] = None, column_instructions: Dict[Any, Any] = None, fillna: Optional[int] = None, enable_regex: bool = False) -> pyspark.sql.dataframe.DataFrame`                                                                                                              | `(df_with_tags: pyspark.sql.dataframe.DataFrame, tags_to_convert: List[str], tag_col_name: str = 'tags', params_keep_cols: Optional[List[str]] = None, key_cols: Optional[List[str]] = None, column_instructions: Optional[Dict[Any, Any]] = None, fillna: Optional[int] = None, enable_regex: bool = False) -> pyspark.sql.dataframe.DataFrame`                                                                                                             |
| 19 | `feature_generation.v1.core.tags.expand_tags.expand_tags_all`                        | Change | `(df_with_tags: pyspark.sql.dataframe.DataFrame, tag_col_name: str = 'tags', params_keep_cols: List[str] = None, key_cols: List[str] = None, column_instructions: Dict[Any, Any] = None, fillna: Optional[int] = None, enable_regex: bool = False) -> pyspark.sql.dataframe.DataFrame`                                                                                                                                          | `(df_with_tags: pyspark.sql.dataframe.DataFrame, tag_col_name: str = 'tags', params_keep_cols: Optional[List[str]] = None, key_cols: Optional[List[str]] = None, column_instructions: Optional[Dict[Any, Any]] = None, fillna: Optional[int] = None, enable_regex: bool = False) -> pyspark.sql.dataframe.DataFrame`                                                                                                                                         |
| 20 | `feature_generation.v1.core.tags.expand_tags.expand_tags_with_spine`                 | Change | `(df_with_tags: pyspark.sql.dataframe.DataFrame, df_spine: pyspark.sql.dataframe.DataFrame, spine_cols: List[str], tags_to_convert: List[str], tag_col_name: str = 'tags', params_keep_cols: str = None, key_cols: List[str] = None, column_instructions: Dict[Any, Any] = None, fillna: Optional[int] = None) -> pyspark.sql.dataframe.DataFrame`                                                                              | `(df_with_tags: pyspark.sql.dataframe.DataFrame, df_spine: pyspark.sql.dataframe.DataFrame, spine_cols: List[str], tags_to_convert: List[str], tag_col_name: str = 'tags', params_keep_cols: Optional[str] = None, key_cols: Optional[List[str]] = None, column_instructions: Optional[Dict[Any, Any]] = None, fillna: Optional[int] = None) -> pyspark.sql.dataframe.DataFrame`                                                                             |
| 21 | `feature_generation.v1.core.timeseries.array_collect.collect_array_then_interpolate` | Change | `(df: pyspark.sql.dataframe.DataFrame, order: str, values: Union[str, List[str]], groupby: Union[str, List[str]], interpolate_func: Callable, desc: bool = False, spine: str = None, delta: int = 1, **interpolate_func_kwargs) -> pyspark.sql.dataframe.DataFrame`                                                                                                                                                             | `(df: pyspark.sql.dataframe.DataFrame, order: str, values: Union[str, List[str]], groupby: Union[str, List[str]], interpolate_func: Callable, desc: bool = False, spine: Optional[str] = None, delta: int = 1, **interpolate_func_kwargs) -> pyspark.sql.dataframe.DataFrame`                                                                                                                                                                                |
| 22 | `feature_generation.v1.core.timeseries.array_transform.interpolate_constant`         | Change | `(spine_index: str, time_index: str, value: str, constant: float = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                          | `(spine_index: str, time_index: str, value: str, constant: Optional[float] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                                             |
| 23 | `feature_generation.v1.core.utils.strings.mask_string`                               | Change | `(column: str, regexp_replace_dict: Dict = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                                                  | `(column: str, regexp_replace_dict: Optional[Dict] = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                                                                     |
| 24 | `feature_generation.v1.core.utils.strings.regex_map_values_from_dict`                | Change | `(column: str, mapping: Dict[str, Union[str, List[str]]], other: str = None, coalesce: bool = False) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                              | `(column: str, mapping: Dict[str, Union[str, List[str]]], other: Optional[str] = None, coalesce: bool = False) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                 |

## 0.6.1
No function/method signature changes done in this version.

## 0.6.0
|    | Function Name                                                     | Type    | Old Signature                                                                                                                                                                                                                                                                                                                                                                          | New Signature                                                                                                                                                                                    |
|---:|:------------------------------------------------------------------|:--------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | `feature_generation.v1.core.features.flags.arrays_overlap`        | Change  | `(inputs: Union[str, int, List[str], List[int]], values: Union[str, List[str]], outputs: Union[str, List[str]], return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                | `(input: str, values: Union[str, List[str]], output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                |
|  1 | `feature_generation.v1.core.features.flags.coalesce`              | Change  | `(outputs: str, cols: List[str]) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                         | `(output: str, cols: List[str]) -> pyspark.sql.column.Column`                                                                                                                                    |
|  2 | `feature_generation.v1.core.features.flags.expr_col`              | Change  | `(expr: str, outputs: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                                               | `(expr: str, output: str) -> pyspark.sql.column.Column`                                                                                                                                          |
|  3 | `feature_generation.v1.core.features.flags.expr_flag`             | Change  | `(expr: str, outputs: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                     | `(expr: str, output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                |
|  4 | `feature_generation.v1.core.features.flags.isin`                  | Change  | `(inputs: Union[str, List[str]], values: List[str], outputs: Union[str, List[str]], return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                            | `(input: str, values: List[str], output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                            |
|  5 | `feature_generation.v1.core.features.flags.nth_occurrence`        | Change  | `(outputs: str, inputs: str, values: str, window: Dict[str, Union[str, List[str]]], n: int, return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                    | `(output: str, input: str, values: str, window: Dict[str, Union[str, List[str]]], n: int, return_value: str = None) -> pyspark.sql.column.Column`                                                |
|  6 | `feature_generation.v1.core.features.flags.null`                  | Change  | `(inputs: str, values: bool, outputs: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                               | `(input: str, values: bool, output: str) -> pyspark.sql.column.Column`                                                                                                                           |
|  7 | `feature_generation.v1.core.features.flags.regexp_extract`        | Change  | `(inputs: str, values: Union[str, List[str]], outputs: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                              | `(input: str, values: Union[str, List[str]], output: str) -> pyspark.sql.column.Column`                                                                                                          |
|  8 | `feature_generation.v1.core.features.flags.rlike`                 | Change  | `(inputs: Union[str, List[str]], values: Union[str, List[str]], outputs: Union[str, List[str]], return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                | `(input: str, values: Union[str, List[str]], output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                |
|  9 | `feature_generation.v1.core.features.flags.rlike_extract`         | Change  | `(inputs: Union[str, List[str]], values: List[str], outputs: Union[str, List[str]], suffix: str = None, return_value: str = None) -> List[pyspark.sql.column.Column]`                                                                                                                                                                                                                  | `(input: str, values: List[str], output: str, suffix: str = None, return_value: str = None) -> List[pyspark.sql.column.Column]`                                                                  |
| 10 | `feature_generation.v1.core.features.flags.tag_arrays_overlap`    | Change  | `(inputs: Union[str, int, List[str], List[int]], values: Union[str, List[str]], outputs: Union[str, List[str]], return_value: str = None) -> pyspark.sql.column.Column`                                                                                                                                                                                                                | `(input: str, values: Union[str, List[str]], output: str, return_value: str = None) -> pyspark.sql.column.Column`                                                                                |
| 11 | `feature_generation.v1.core.features.windows.window_column`       | Change  | `(outputs: Union[str, List[str]], inputs: pyspark.sql.column.Column, windows_spec: Union[pyspark.sql.window.WindowSpec, List[pyspark.sql.window.WindowSpec]]) -> List[pyspark.sql.column.Column]`                                                                                                                                                                                      | `(outputs: Union[str, List[str]], input: pyspark.sql.column.Column, windows_spec: Union[pyspark.sql.window.WindowSpec, List[pyspark.sql.window.WindowSpec]]) -> List[pyspark.sql.column.Column]` |
| 12 | `feature_generation.v1.core.tags.tags.array_contains_all`         | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 13 | `feature_generation.v1.core.tags.tags.array_not_contains_all`     | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 14 | `feature_generation.v1.core.tags.tags.array_rlike`                | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 15 | `feature_generation.v1.core.tags.tags.arrays_not_overlap`         | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 16 | `feature_generation.v1.core.tags.tags.arrays_overlap`             | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 17 | `feature_generation.v1.core.tags.tags.count_and_compare_tags`     | Change  | `(tag: str, inputs: Union[str, pyspark.sql.column.Column], values: Union[str, List[str]], operator: Callable, y: Union[int, float]) -> pyspark.sql.column.Column`                                                                                                                                                                                                                      | `(tag: str, input: Union[str, pyspark.sql.column.Column], values: Union[str, List[str]], operator: Callable, y: Union[int, float]) -> pyspark.sql.column.Column`                                 |
| 18 | `feature_generation.v1.core.tags.tags.isin`                       | Change  | `(inputs: str, values: List[str], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                              | `(input: str, values: List[str], tag: str) -> pyspark.sql.column.Column`                                                                                                                         |
| 19 | `feature_generation.v1.core.tags.tags.nth_occurrence`             | Change  | `(tag: str, inputs: str, values: str, partition_by: Union[str, List[str]], order_by: Union[str, List[str]], n: int, descending: bool = False) -> pyspark.sql.column.Column`                                                                                                                                                                                                            | `(tag: str, input: str, values: str, partition_by: Union[str, List[str]], order_by: Union[str, List[str]], n: int, descending: bool = False) -> pyspark.sql.column.Column`                       |
| 20 | `feature_generation.v1.core.tags.tags.rlike`                      | Change  | `(inputs: str, values: List[str], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                              | `(input: str, values: List[str], tag: str) -> pyspark.sql.column.Column`                                                                                                                         |
| 21 | `feature_generation.v1.core.tags.tags.rlike_multi_col`            | Change  | `(inputs: Dict[str, str], tag: str, operator: Callable = <built-in function or_>) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                        | `(inputs: List[Dict[str, str]], tag: str, operator: Callable = <built-in function or_>) -> pyspark.sql.column.Column`                                                                            |
| 22 | `feature_generation.v1.core.tags.tags.tag_array_contains_all`     | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 23 | `feature_generation.v1.core.tags.tags.tag_array_not_contains_all` | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 24 | `feature_generation.v1.core.tags.tags.tag_array_rlike`            | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 25 | `feature_generation.v1.core.tags.tags.tag_arrays_not_overlap`     | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 26 | `feature_generation.v1.core.tags.tags.tag_arrays_overlap`         | Change  | `(inputs: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                  | `(input: str, values: Union[str, List[str]], tag: str) -> pyspark.sql.column.Column`                                                                                                             |
| 27 | `feature_generation.v1.core.tags.tags.window_tag`                 | Removal | `(tag: Union[str, List[str]], inputs: str, tag_function: Callable, values: Union[str, List[str]], partition_by: Union[str, List[str]], order_by: Union[str, List[str]], range_between: Union[List[Union[int, str]], List[List[Union[int, str]]]] = None, rows_between: Union[List[Union[int, str]], List[List[Union[int, str]]]] = None, **kwargs) -> List[pyspark.sql.column.Column]` | `NA`                                                                                                                                                                                             |
| 28 | `feature_generation.v1.core.utils.arrays.arr_rlike`               | Change  | `(inputs: str, pattern: Union[str, List[str]]) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                           | `(input: str, pattern: Union[str, List[str]]) -> pyspark.sql.column.Column`                                                                                                                      |
| 29 | `feature_generation.v1.core.utils.arrays.array_rlike`             | Change  | `(inputs: str, pattern: Union[str, List[str]]) -> pyspark.sql.column.Column`                                                                                                                                                                                                                                                                                                           | `(input: str, pattern: Union[str, List[str]]) -> pyspark.sql.column.Column`                                                                                                                      |

## 0.5.2
|    | Function Name                                     | Type   | Old Signature                                                                                                                               | New Signature                                                                                                                                           |
|---:|:--------------------------------------------------|:-------|:--------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | `feature_generation.v1.core.features.flags.rlike` | Change | `(inputs: Union[str, List[str]], values: List[str], outputs: Union[str, List[str]], return_value: str = None) -> pyspark.sql.column.Column` | `(inputs: Union[str, List[str]], values: Union[str, List[str]], outputs: Union[str, List[str]], return_value: str = None) -> pyspark.sql.column.Column` |

## 0.5.1
No function/method signature changes done in this version.

## 0.5.0
|    | Function Name                                                                     | Type     | Old Signature                                                                                                                                                                                                                                                                                                                     | New Signature                                                                                                                                                                                                                                                                                                                                                                                                                   |
|---:|:----------------------------------------------------------------------------------|:---------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | `feature_generation.v1.core.features.windows.aggregate_over_collect_list`         | Addition | `NA`                                                                                                                                                                                                                                                                                                                              | `(input_column: pyspark.sql.column.Column, outputs: Union[str, List[str]], windows_spec: Union[pyspark.sql.window.WindowSpec, List[pyspark.sql.window.WindowSpec]], agg_function: Callable) -> List[pyspark.sql.column.Column]`                                                                                                                                                                                                 |
|  1 | `feature_generation.v1.core.features.windows.aggregate_over_slice_grid`           | Addition | `NA`                                                                                                                                                                                                                                                                                                                              | `(inputs: List[str], anchor_col: str, anchor_array: List[str], funcs: List[str], ranges_between: List[List[Union[int, str]]], positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]`                                                                                               |
|  2 | `feature_generation.v1.core.features.windows.generate_array_elements_window_grid` | Addition | `NA`                                                                                                                                                                                                                                                                                                                              | `(inputs: List[str], windows: List[Dict[str, List[str]]], agg_functions: List[Callable], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]]` |
|  3 | `feature_generation.v1.core.timeseries.array_aggregate.aggregate_over_slice_grid` | Removal  | `(inputs: List[str], anchor_col: str, anchor_array: List[str], funcs: List[str], ranges_between: List[List[Union[int, str]]], positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]` | `NA`                                                                                                                                                                                                                                                                                                                                                                                                                            |

## 0.4.4
No function/method signature changes done in this version.

## 0.4.3
No function/method signature changes done in this version.

## 0.4.2
No function/method signature changes done in this version.

## 0.4.1
No function/method signature changes done in this version.

## 0.4.0
|    | Function Name                                                                     | Type   | Old Signature                                                                                                                                                                                                                                                                                                                                              | New Signature                                                                                                                                                                                                                                                                                                                                                                                                                |
|---:|:----------------------------------------------------------------------------------|:-------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | feature_generation.v1.core.features.windows.generate_distinct_element_window_grid | Change | (inputs: List[str], windows: List[Dict[str, List[str]]], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', agg_func_name: str = 'count', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]] | (inputs: List[str], windows: List[Dict[str, List[str]]], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', agg_func_name: str = 'count', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]] |
|  1 | feature_generation.v1.core.features.windows.generate_window_delta                 | Change | (inputs: List[str], funcs: List[Callable], windows: List[Dict[str, List[str]]], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]                                     | (inputs: List[str], funcs: List[Callable], windows: List[Dict[str, List[str]]], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]                                     |
|  2 | feature_generation.v1.core.features.windows.generate_window_grid                  | Change | (funcs: List[Callable], windows: List[Dict[str, List[str]]], inputs: List[str] = None, ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]] | (funcs: List[Callable], windows: List[Dict[str, List[str]]], inputs: List[str] = None, ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> Union[List[Dict[Any, Any]], List[pyspark.sql.column.Column]] |
|  3 | feature_generation.v1.core.features.windows.generate_window_ratio                 | Change | (inputs: Dict[Any, Any], funcs: List[Callable], windows: List[Dict[str, List[str]]], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]                                | (inputs: Dict[Any, Any], funcs: List[Callable], windows: List[Dict[str, List[str]]], ranges_between: List[List[Union[int, str]]] = None, rows_between: List[List[Union[int, str]]] = None, positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]                                |
|  4 | feature_generation.v1.core.timeseries.array_aggregate.aggregate_over_slice_grid   | Change | (inputs: List[str], anchor_col: str, anchor_array: List[str], funcs: List[str], ranges_between: List[List[Union[int, str]]], positive_term: str = 'next', negative_term: str = 'past', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]                                                                                              | (inputs: List[str], anchor_col: str, anchor_array: List[str], funcs: List[str], ranges_between: List[List[Union[int, str]]], positive_term: str = 'next', negative_term: str = 'past', negative_default: str = 'between', positive_default: str = 'and', prefix: str = '', suffix: str = '') -> List[pyspark.sql.column.Column]                                                                                              |

## 0.3.1
No function/method signature changes done in this version.

## 0.3.0
No function/method signature changes done in this version.

## 0.2.9
